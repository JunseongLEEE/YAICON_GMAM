import json
import os
import numpy as np
# import pandas as pd  # ì œê±°
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import statistics
import csv

def extract_numeric_values(data, target_keys=None):
    """JSON ë°ì´í„°ì—ì„œ ìˆ«ì ê°’ë“¤ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    if target_keys is None:
        target_keys = ['Yes', 'No', 'raw_yes', 'raw_no', 'total_yes_no']
    
    extracted_values = defaultdict(list)
    
    if isinstance(data, dict):
        for key, value in data.items():
            if isinstance(value, dict):
                # ê° í•­ëª©ì˜ recognitionê³¼ raw_probabilities ê°’ë“¤ ì¶”ì¶œ
                if 'recognition' in value:
                    for rec_key, rec_value in value['recognition'].items():
                        if isinstance(rec_value, (int, float)):
                            extracted_values[f'recognition_{rec_key}'].append(rec_value)
                
                if 'raw_probabilities' in value:
                    for raw_key, raw_value in value['raw_probabilities'].items():
                        if isinstance(raw_value, (int, float)):
                            extracted_values[f'raw_probabilities_{raw_key}'].append(raw_value)
                
                # Summary í´ë”ì˜ Pairwise íŒŒì¼ì˜ confidence í•„ë“œë“¤ ì¶”ì¶œ
                if 'recognition_confidence' in value and isinstance(value['recognition_confidence'], (int, float)):
                    extracted_values['recognition_confidence'].append(value['recognition_confidence'])
                
                if 'preference_confidence' in value and isinstance(value['preference_confidence'], (int, float)):
                    extracted_values['preference_confidence'].append(value['preference_confidence'])
                
                # Story í´ë”ì˜ Pairwise íŒŒì¼: first_orderì™€ second_orderì˜ gemma_prob í‰ê·  ê³„ì‚°
                if 'details' in value and isinstance(value['details'], dict):
                    details = value['details']
                    if ('first_order' in details and 'second_order' in details and
                        isinstance(details['first_order'], dict) and isinstance(details['second_order'], dict)):
                        
                        first_gemma_prob = details['first_order'].get('gemma_prob')
                        second_gemma_prob = details['second_order'].get('gemma_prob')
                        
                        if (isinstance(first_gemma_prob, (int, float)) and 
                            isinstance(second_gemma_prob, (int, float))):
                            # first_orderì™€ second_orderì˜ gemma_prob í‰ê·  ê³„ì‚°
                            avg_gemma_prob = (first_gemma_prob + second_gemma_prob) / 2
                            extracted_values['pairwise_gemma_confidence'].append(avg_gemma_prob)
                
                # ë‹¤ë¥¸ ìˆ«ì ê°’ë“¤ë„ ì¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ
                nested_values = extract_numeric_values(value, target_keys)
                for nested_key, nested_list in nested_values.items():
                    extracted_values[nested_key].extend(nested_list)
            
            elif isinstance(value, (int, float)):
                # confidence, score, probabilityê°€ í¬í•¨ëœ í‚¤ë“¤ ì¶”ì¶œ
                if any(target in key.lower() for target in ['confidence', 'score', 'probability']):
                    extracted_values[key].append(value)
                # íŠ¹ì • í‚¤ ì´ë¦„ë“¤ë„ ì§ì ‘ ì¶”ì¶œ
                elif key in ['recognition_confidence', 'preference_confidence', 'average_recognition_confidence', 'average_preference_confidence', 'high_confidence_ratio']:
                    extracted_values[key].append(value)
    
    elif isinstance(data, list):
        for item in data:
            nested_values = extract_numeric_values(item, target_keys)
            for nested_key, nested_list in nested_values.items():
                extracted_values[nested_key].extend(nested_list)
    
    return extracted_values

def calculate_statistics(values):
    """ê°’ë“¤ì˜ í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œê°’, ìµœëŒ€ê°’ì„ ê³„ì‚°"""
    if not values:
        return None
    
    return {
        'count': len(values),
        'mean': np.mean(values),
        'std': np.std(values, ddof=1) if len(values) > 1 else 0,
        'min': np.min(values),
        'max': np.max(values),
        'median': np.median(values)
    }

def analyze_json_files(base_path):
    """JSON íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ í†µê³„ë¥¼ ê³„ì‚°í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    
    results = {}
    folders_to_check = ['Summary', 'Story']
    
    for main_folder in folders_to_check:
        folder_path = Path(base_path) / main_folder
        if not folder_path.exists():
            print(f"âŒ {main_folder} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            continue
        
        results[main_folder] = {}
        print(f"\nğŸ” {main_folder} í´ë” ë¶„ì„ ì¤‘...")
        
        # í•˜ìœ„ í´ë”ë“¤ ìˆœíšŒ
        for subfolder in folder_path.iterdir():
            if subfolder.is_dir():
                subfolder_name = subfolder.name
                results[main_folder][subfolder_name] = {}
                print(f"  ğŸ“ {subfolder_name}/ ë¶„ì„ ì¤‘...")
                
                # JSON íŒŒì¼ë“¤ í™•ì¸
                json_files = list(subfolder.glob("*.json"))
                if not json_files:
                    print(f"    âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                for json_file in json_files:
                    file_name = json_file.name
                    print(f"    ğŸ“„ {file_name} ì²˜ë¦¬ ì¤‘...")
                    
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # ìˆ«ì ê°’ë“¤ ì¶”ì¶œ
                        extracted_values = extract_numeric_values(data)
                        
                        # ê° í‚¤ì— ëŒ€í•œ í†µê³„ ê³„ì‚°
                        file_stats = {}
                        for key, values in extracted_values.items():
                            if values:  # ê°’ì´ ìˆëŠ” ê²½ìš°ë§Œ
                                stats = calculate_statistics(values)
                                if stats:
                                    file_stats[key] = stats
                        
                        if file_stats:
                            results[main_folder][subfolder_name][file_name] = file_stats
                        
                    except json.JSONDecodeError as e:
                        print(f"    âŒ JSON íŒŒì‹± ì˜¤ë¥˜ ({file_name}): {e}")
                    except Exception as e:
                        print(f"    âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({file_name}): {e}")
        
        # ë©”ì¸ í´ë”ì˜ JSON íŒŒì¼ë“¤ë„ í™•ì¸
        main_json_files = list(folder_path.glob("*.json"))
        if main_json_files:
            results[main_folder]['main_folder'] = {}
            for json_file in main_json_files:
                file_name = json_file.name
                print(f"  ğŸ“„ {file_name} (ë©”ì¸ í´ë”) ì²˜ë¦¬ ì¤‘...")
                
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    extracted_values = extract_numeric_values(data)
                    
                    file_stats = {}
                    for key, values in extracted_values.items():
                        if values:
                            stats = calculate_statistics(values)
                            if stats:
                                file_stats[key] = stats
                    
                    if file_stats:
                        results[main_folder]['main_folder'][file_name] = file_stats
                
                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜ ({file_name}): {e}")
    
    return results

def save_results_to_files(results):
    """ê²°ê³¼ë¥¼ ì—¬ëŸ¬ í˜•íƒœë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # 1. ìƒì„¸ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    detailed_filename = f"detailed_statistics_{timestamp}.json"
    with open(detailed_filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"âœ… ìƒì„¸ ê²°ê³¼ê°€ '{detailed_filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ìš”ì•½ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì €ì¥
    summary_filename = f"statistics_summary_{timestamp}.txt"
    with open(summary_filename, 'w', encoding='utf-8') as f:
        f.write(f"JSON íŒŒì¼ í†µê³„ ë¶„ì„ ìš”ì•½\n")
        f.write(f"ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 80 + "\n\n")
        
        for main_folder, subfolders in results.items():
            f.write(f"ğŸ“ {main_folder} í´ë”\n")
            f.write("-" * 50 + "\n")
            
            for subfolder_name, files in subfolders.items():
                f.write(f"\n  ğŸ“‚ {subfolder_name}/\n")
                
                for file_name, stats in files.items():
                    f.write(f"\n    ğŸ“„ {file_name}\n")
                    
                    for metric_name, metric_stats in stats.items():
                        f.write(f"      ğŸ”¢ {metric_name}:\n")
                        f.write(f"        ê°œìˆ˜: {metric_stats['count']}\n")
                        f.write(f"        í‰ê· : {metric_stats['mean']:.6f}\n")
                        f.write(f"        í‘œì¤€í¸ì°¨: {metric_stats['std']:.6f}\n")
                        f.write(f"        ìµœì†Œê°’: {metric_stats['min']:.6f}\n")
                        f.write(f"        ìµœëŒ€ê°’: {metric_stats['max']:.6f}\n")
                        f.write(f"        ì¤‘ì•™ê°’: {metric_stats['median']:.6f}\n")
                        f.write("\n")
            f.write("\n")
    
    print(f"âœ… ìš”ì•½ ê²°ê³¼ê°€ '{summary_filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 3. CSV í˜•íƒœë¡œë„ ì €ì¥ (pandas ëŒ€ì‹  csv ëª¨ë“ˆ ì‚¬ìš©)
    csv_data = []
    for main_folder, subfolders in results.items():
        for subfolder_name, files in subfolders.items():
            for file_name, stats in files.items():
                for metric_name, metric_stats in stats.items():
                    csv_data.append({
                        'main_folder': main_folder,
                        'subfolder': subfolder_name,
                        'file_name': file_name,
                        'metric': metric_name,
                        'count': metric_stats['count'],
                        'mean': metric_stats['mean'],
                        'std': metric_stats['std'],
                        'min': metric_stats['min'],
                        'max': metric_stats['max'],
                        'median': metric_stats['median']
                    })
    
    if csv_data:
        csv_filename = f"statistics_data_{timestamp}.csv"
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['main_folder', 'subfolder', 'file_name', 'metric', 'count', 'mean', 'std', 'min', 'max', 'median']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(csv_data)
        print(f"âœ… CSV ë°ì´í„°ê°€ '{csv_filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def print_summary_statistics(results):
    """ì£¼ìš” í†µê³„ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("ğŸ“Š ì£¼ìš” í†µê³„ ìš”ì•½")
    print("="*80)
    
    for main_folder, subfolders in results.items():
        print(f"\nğŸ” {main_folder} í´ë”")
        print("-" * 50)
        
        # Recognition Yes/No í†µê³„ ìˆ˜ì§‘
        all_yes_values = []
        all_no_values = []
        
        # Pairwise confidence í†µê³„ ìˆ˜ì§‘
        recognition_confidence_values = []
        preference_confidence_values = []
        pairwise_gemma_confidence_values = []  # Story í´ë”ìš©
        
        for subfolder_name, files in subfolders.items():
            for file_name, stats in files.items():
                if 'recognition_Yes' in stats:
                    # ì´ íŒŒì¼ì˜ ëª¨ë“  Yes ê°’ë“¤ì„ ê°€ì ¸ì™€ì„œ í‰ê·  ê³„ì‚°
                    yes_mean = stats['recognition_Yes']['mean']
                    all_yes_values.append(yes_mean)
                
                if 'recognition_No' in stats:
                    no_mean = stats['recognition_No']['mean']
                    all_no_values.append(no_mean)
                
                # Summary í´ë”ì˜ Pairwise confidence ê°’ë“¤ ìˆ˜ì§‘
                if 'recognition_confidence' in stats:
                    recognition_confidence_values.append(stats['recognition_confidence']['mean'])
                
                if 'preference_confidence' in stats:
                    preference_confidence_values.append(stats['preference_confidence']['mean'])
                
                # Story í´ë”ì˜ Pairwise confidence ê°’ë“¤ ìˆ˜ì§‘
                if 'pairwise_gemma_confidence' in stats:
                    pairwise_gemma_confidence_values.append(stats['pairwise_gemma_confidence']['mean'])
        
        if all_yes_values:
            print(f"  ğŸ¯ Recognition 'Yes' ì ìˆ˜:")
            print(f"    ì „ì²´ í‰ê· : {np.mean(all_yes_values):.4f}")
            print(f"    í‘œì¤€í¸ì°¨: {np.std(all_yes_values, ddof=1):.4f}")
            print(f"    ë²”ìœ„: {np.min(all_yes_values):.4f} ~ {np.max(all_yes_values):.4f}")
        
        if all_no_values:
            print(f"  ğŸ¯ Recognition 'No' ì ìˆ˜:")
            print(f"    ì „ì²´ í‰ê· : {np.mean(all_no_values):.4f}")
            print(f"    í‘œì¤€í¸ì°¨: {np.std(all_no_values, ddof=1):.4f}")
            print(f"    ë²”ìœ„: {np.min(all_no_values):.4f} ~ {np.max(all_no_values):.4f}")
        
        if recognition_confidence_values:
            print(f"  ğŸ¯ Pairwise Recognition Confidence:")
            print(f"    ì „ì²´ í‰ê· : {np.mean(recognition_confidence_values):.4f}")
            print(f"    í‘œì¤€í¸ì°¨: {np.std(recognition_confidence_values, ddof=1):.4f}")
            print(f"    ë²”ìœ„: {np.min(recognition_confidence_values):.4f} ~ {np.max(recognition_confidence_values):.4f}")
        
        if preference_confidence_values:
            print(f"  ğŸ¯ Pairwise Preference Confidence:")
            print(f"    ì „ì²´ í‰ê· : {np.mean(preference_confidence_values):.4f}")
            print(f"    í‘œì¤€í¸ì°¨: {np.std(preference_confidence_values, ddof=1):.4f}")
            print(f"    ë²”ìœ„: {np.min(preference_confidence_values):.4f} ~ {np.max(preference_confidence_values):.4f}")
        
        if pairwise_gemma_confidence_values:
            print(f"  ğŸ¯ Pairwise Gemma Confidence (Story):")
            print(f"    ì „ì²´ í‰ê· : {np.mean(pairwise_gemma_confidence_values):.4f}")
            print(f"    í‘œì¤€í¸ì°¨: {np.std(pairwise_gemma_confidence_values, ddof=1):.4f}")
            print(f"    ë²”ìœ„: {np.min(pairwise_gemma_confidence_values):.4f} ~ {np.max(pairwise_gemma_confidence_values):.4f}")

if __name__ == "__main__":
    print("ğŸš€ JSON íŒŒì¼ í†µê³„ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
    base_path = "."
    
    try:
        # ë¶„ì„ ì‹¤í–‰
        results = analyze_json_files(base_path)
        
        if results:
            # ê²°ê³¼ ì¶œë ¥
            print_summary_statistics(results)
            
            # íŒŒì¼ë¡œ ì €ì¥
            save_results_to_files(results)
            
            print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
        else:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc() 