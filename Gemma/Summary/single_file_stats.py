import json
import numpy as np
from datetime import datetime
from collections import defaultdict

def analyze_single_file(file_path):
    """ë‹¨ì¼ JSON íŒŒì¼ì˜ í†µê³„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    
    print(f"ğŸ” ë¶„ì„ íŒŒì¼: {file_path}")
    print("=" * 60)
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # í†µê³„ ìˆ˜ì§‘ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ë“¤
        yes_values = []
        no_values = []
        raw_yes_values = []
        raw_no_values = []
        raw_total_values = []
        
        # results ì•ˆì˜ ë°ì´í„° ìˆœíšŒ
        if 'results' in data:
            results = data['results']
            
            for item_id, item_data in results.items():
                # recognition ê°’ë“¤ ìˆ˜ì§‘
                if 'recognition' in item_data:
                    recognition = item_data['recognition']
                    if 'Yes' in recognition:
                        yes_values.append(recognition['Yes'])
                    if 'No' in recognition:
                        no_values.append(recognition['No'])
                
                # raw_probabilities ê°’ë“¤ ìˆ˜ì§‘
                if 'raw_probabilities' in item_data:
                    raw_probs = item_data['raw_probabilities']
                    if 'yes' in raw_probs:
                        raw_yes_values.append(raw_probs['yes'])
                    if 'no' in raw_probs:
                        raw_no_values.append(raw_probs['no'])
                    if 'total' in raw_probs:
                        raw_total_values.append(raw_probs['total'])
        
        # í†µê³„ ê³„ì‚° ë° ì¶œë ¥
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ (ì´ {len(yes_values)}ê°œ í•­ëª©)")
        print("-" * 40)
        
        if yes_values:
            print(f"ğŸ¯ Recognition 'Yes' ì ìˆ˜:")
            print(f"  ê°œìˆ˜: {len(yes_values)}")
            print(f"  í‰ê· : {np.mean(yes_values):.6f}")
            print(f"  í‘œì¤€í¸ì°¨: {np.std(yes_values, ddof=1):.6f}")
            print(f"  ìµœì†Œê°’: {np.min(yes_values):.6f}")
            print(f"  ìµœëŒ€ê°’: {np.max(yes_values):.6f}")
            print(f"  ì¤‘ì•™ê°’: {np.median(yes_values):.6f}")
            print()
        
        if no_values:
            print(f"ğŸ¯ Recognition 'No' ì ìˆ˜:")
            print(f"  ê°œìˆ˜: {len(no_values)}")
            print(f"  í‰ê· : {np.mean(no_values):.6f}")
            print(f"  í‘œì¤€í¸ì°¨: {np.std(no_values, ddof=1):.6f}")
            print(f"  ìµœì†Œê°’: {np.min(no_values):.6f}")
            print(f"  ìµœëŒ€ê°’: {np.max(no_values):.6f}")
            print(f"  ì¤‘ì•™ê°’: {np.median(no_values):.6f}")
            print()
        
        if raw_yes_values:
            print(f"ğŸ¯ Raw Probabilities 'Yes':")
            print(f"  ê°œìˆ˜: {len(raw_yes_values)}")
            print(f"  í‰ê· : {np.mean(raw_yes_values):.8f}")
            print(f"  í‘œì¤€í¸ì°¨: {np.std(raw_yes_values, ddof=1):.8f}")
            print(f"  ìµœì†Œê°’: {np.min(raw_yes_values):.8f}")
            print(f"  ìµœëŒ€ê°’: {np.max(raw_yes_values):.8f}")
            print(f"  ì¤‘ì•™ê°’: {np.median(raw_yes_values):.8f}")
            print()
        
        if raw_no_values:
            print(f"ğŸ¯ Raw Probabilities 'No':")
            print(f"  ê°œìˆ˜: {len(raw_no_values)}")
            print(f"  í‰ê· : {np.mean(raw_no_values):.8f}")
            print(f"  í‘œì¤€í¸ì°¨: {np.std(raw_no_values, ddof=1):.8f}")
            print(f"  ìµœì†Œê°’: {np.min(raw_no_values):.8f}")
            print(f"  ìµœëŒ€ê°’: {np.max(raw_no_values):.8f}")
            print(f"  ì¤‘ì•™ê°’: {np.median(raw_no_values):.8f}")
            print()
        
        if raw_total_values:
            print(f"ğŸ¯ Raw Probabilities 'Total':")
            print(f"  ê°œìˆ˜: {len(raw_total_values)}")
            print(f"  í‰ê· : {np.mean(raw_total_values):.8f}")
            print(f"  í‘œì¤€í¸ì°¨: {np.std(raw_total_values, ddof=1):.8f}")
            print(f"  ìµœì†Œê°’: {np.min(raw_total_values):.8f}")
            print(f"  ìµœëŒ€ê°’: {np.max(raw_total_values):.8f}")
            print(f"  ì¤‘ì•™ê°’: {np.median(raw_total_values):.8f}")
            print()
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"gemini_recognition_stats_{timestamp}.txt"
        
        with open(output_filename, 'w', encoding='utf-8') as f:
            f.write(f"Gemini Summary Individual Recognition í†µê³„ ë¶„ì„\n")
            f.write(f"ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"íŒŒì¼: {file_path}\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"ì´ ë¶„ì„ í•­ëª© ìˆ˜: {len(yes_values)}\n\n")
            
            if yes_values:
                f.write("Recognition 'Yes' ì ìˆ˜:\n")
                f.write(f"  í‰ê· : {np.mean(yes_values):.6f}\n")
                f.write(f"  í‘œì¤€í¸ì°¨: {np.std(yes_values, ddof=1):.6f}\n")
                f.write(f"  ìµœì†Œê°’: {np.min(yes_values):.6f}\n")
                f.write(f"  ìµœëŒ€ê°’: {np.max(yes_values):.6f}\n")
                f.write(f"  ì¤‘ì•™ê°’: {np.median(yes_values):.6f}\n\n")
            
            if no_values:
                f.write("Recognition 'No' ì ìˆ˜:\n")
                f.write(f"  í‰ê· : {np.mean(no_values):.6f}\n")
                f.write(f"  í‘œì¤€í¸ì°¨: {np.std(no_values, ddof=1):.6f}\n")
                f.write(f"  ìµœì†Œê°’: {np.min(no_values):.6f}\n")
                f.write(f"  ìµœëŒ€ê°’: {np.max(no_values):.6f}\n")
                f.write(f"  ì¤‘ì•™ê°’: {np.median(no_values):.6f}\n\n")
        
        print(f"âœ… í†µê³„ ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return False
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

if __name__ == "__main__":
    file_path = "/Users/ijunseong/Desktop/YAI/YAICON2025/Summary/Individual_Recognition_result/gemini_summary_individual_recognition.json"
    analyze_single_file(file_path) 